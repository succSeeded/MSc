% !TeX spellcheck = en_GB
% !TeX encoding = UTF-8 

\documentclass[14pt,a4paper]{extarticle}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{setspace} 
\usepackage[a4paper,
			left=30mm,
			right=10mm,
			top=20mm,
			bottom=20mm]{geometry}
\usepackage{amsmath,amssymb,amsthm, bm}
\usepackage{cite}
\usepackage{graphicx} 
\usepackage{subfigure,subcaption}
\usepackage{kprjHSE} 
\usepackage{tikz}
\usepackage{xcolor,tabularray}
\usepackage{wrapfig}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,      
	urlcolor=blue,
}

\usetikzlibrary{positioning}

\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

\lstset{
	frame=single,
	basicstyle=\ttfamily,
	breaklines=true,
	tabsize=4
}

\LabWork
\title{Gaussian processes}
\setcounter{MaxMatrixCols}{20}

\FirstAuthor{M.D.~Kirdin}
\FirstConsultant{M.A.~Shirokikh}
\discipline{Machine Learning}
\faculty{Faculty of Computer Science}
\chair{School of Data Analysis and Artificial Intelligence}
\workyear{2025}

\onehalfspacing

\begin{document}
	\maketitle
	
	\noindent\textbf{Task 19.} 
	
	Suppose that $\bm{x}=(x_0,\, x_1)^T \sim N(\mu,\, \Sigma)$. Find the distribution of $(a,\, b)^T$ of line $y=ax+b$ passing through points $(0,\, x_0)$ and $(1,\, x_1)$. Derive the distribution and its parameters, implement it and check if it works.
	
	\noindent\textbf{Solution.}
	
	Let us consider a line $y = f(x)$ going from $(0,\, x_0)$ to $(1,\, x_1)$. It is defined by a following expression:
	\[y=\dfrac{x_1-x_0}{1-0}x+x_0.\]
	Therefore, coefficients $a$ and $b$ are equal to $x_1 - x_0$ and $x_0$ respectively. Note that vector $\bm{k}=(a,\,b)^T$ is, in fact, a linear transformation of $\bm{x}$:
	\[\begin{pmatrix} a\\ b\end{pmatrix}=\begin{pmatrix} x_1-x_0 \\ x_0 \end{pmatrix}=\begin{pmatrix}-1 & 1 \\ \phantom{-}1 & 0 \end{pmatrix}\cdot\begin{pmatrix}x_0 \\ x_1\end{pmatrix}=A\bm{x}.\]
	Hence, we can easily deduce the distribution of $\bm{k}$ using characteristic functions (CFs). Since CF for multivariate normal distribution is
	\[\varphi_{X}(t)=E[e^{it^TX}]=\exp\left(it^T\mu-\dfrac{1}{2}t^T\Sigma t\right),\]
	for a linear transform defined by matrix A we get that CF is
	\[\varphi_{AX}(t)=E[e^{it^TAX}]=\varphi_X(A^Tt)=\exp\left(it^TA\mu-\dfrac{1}{2}t^TA\Sigma A^Tt\right).\]
	Therefore $\bm{k} \sim N(A\mu,\, A\Sigma A^T)$.\qed
	\newpage
	
	\noindent\textbf{Task 20.}
	
	Same, but for $\bm{x}=(x_0,\, x_1,\, x_2)^T$ and coefficients of quadratic polynomials passing through all three points $(0,\, x_1), (1,\, x_1), (2,\, x_2)$.
	
	\noindent\textbf{Solution.}
	
	For a second degree polynomial $f(x)=ax^2+bx+c$ its coefficients can be derived from elements of $\bm{x}$ with a linear transform since:
	\begin{equation*}
		\begin{cases}
			\begin{aligned}
				x_0 &= c,\\
				x_1 &= a+b+c,\\
				x_2 &= 4a+2b+c.
			\end{aligned}
		\end{cases}
	\end{equation*}
	Or, in matrix form:
	\[\bm{x}=B^{-1}\bm{k},\]
	where $B^{-1}=\begin{pmatrix}0&0&1\\1&1&1\\4&2&1\end{pmatrix}$ and $\bm{k}=(a,\, b,\, c)^T$. Hence, analogously to the previous task, we get that $\bm{k} \sim N(B\mu,\, B\Sigma B^T)$, where $B=\begin{pmatrix}\phantom{-}\frac{1}{2}&-1&\phantom{-}\frac{1}{2}\\-\frac{3}{2}&\phantom{-}2&-\frac{1}{2}\\\phantom{-}1&\phantom{-}0&\phantom{-}0\end{pmatrix}$.\qed
	\newpage
	
	\noindent\textbf{Task 21.}
	
	Same, but for $\bm{x}=(x_0,\, x_1,\,\dots,\, x_{n})^T$ and coefficients of polynomials with degree $n$ passing through all $n+1$ points $(i,\, x_i),\, i=0,\dots,n$.
	
	\noindent\textbf{Solution.}
	
	It can be proven that the vector of coefficients $\bm{k}=(k_0,\, k_1,\,\dots,\, k_{n})^T$ for a $n$-th degree polynomial $f(x)=k_0x^{n}+k_1x^{n-1}+\dots+k_{n}$, which passes through points $(i,\, x_i),\, i=0,\dots,n$, is a linear transformation of vector $\bm{x}$.

	Since it goes through each point in said set, it holds that:
	\begin{equation*}
		\begin{cases}
			\begin{aligned}
				x_0 &= k_n,\\
				x_1 &= k_0+k_1+\dots+k_{n-1}+k_{n},\\
				& \vdots\\
				x_n &= k_0n^{n}+k_1n^{n-1}+\dots+k_{n-1}n+k_{n}.
			\end{aligned}
		\end{cases}
	\end{equation*}
	Or in matrix form:
	\[\begin{pmatrix}x_0\\x_1\\\vdots\\x_n\end{pmatrix}=\begin{pmatrix}0&0&\dots&0&1\\1&1&\dots&1&1\\\vdots&&&&\vdots\\n^n&n^{n-1}&\dots&n^1&n^0\end{pmatrix}\begin{pmatrix}k_{0}\\k_{1}\\\vdots\\k_{n}\end{pmatrix}.\]
	If we designate the second term as $C^{-1}$, we get that $\bm{x}=C^{-1}\bm{k}$. It indeed follows that $\bm{k}=C\bm{x}$, where $C$ in an inverse of matrix $C^{-1}$. This is a linear transformation, hence, $\bm{k} \sim N(C\mu,\, C\Sigma C^T)$.\qed
\end{document}