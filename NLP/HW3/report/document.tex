% !TeX spellcheck = ru_RU-Russian
% !TeX encoding = UTF-8 

\documentclass[12pt, a4paper]{article}

\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{cmap}
\usepackage{setspace} 
\usepackage[a4paper,
			left=30mm,
			right=10mm,
			top=20mm,
			bottom=20mm]{geometry}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{cite}
\usepackage{subfigure,subcaption}
\usepackage{graphicx}
\usepackage{kprjHSE}
\usepackage{tabularray}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,      
	urlcolor=blue,
}

\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

\lstset{
	frame=single,
	basicstyle=\ttfamily,
	breaklines=true,
	tabsize=4
}

\LabWork
\LabWorkNo{3}
\title{Лексическая семантика}
\variant{E}
\setcounter{MaxMatrixCols}{20}

\FirstAuthor{М.Д.~Кирдин}
\FirstConsultant{Е.И.~Большакова}
\discipline{Компьютерная лингвистика и анализ текстов}
\faculty{Факультет Компьютерных Наук}
\chair{Школа Анализа Данных и Искусственного Интеллекта}
\workyear{2025}

\onehalfspacing

\begin{document}
	\maketitle

	\tableofcontents
	
	\begin{introduction}
		Векторные представления слов, --- также называемые эмбеддингами, --- важная часть современной компьютерной лингвистики. Существует множество способов создания эмбеддингов, в их числе: \textit{word2vec}, \textit{fastText}. Особый интерес представляет их способность сохранять семантические связи между словами. Цель данной работы --- провести исследование данного свойства у предобученных векторных представлений.
	\end{introduction}
	
	\section{Ход работы}
	
	Была поставлена задача провести эксперименты по кластеризации заданного набора слов русского языка, на основе векторного их представления, с целью разбиения набора на семантические/тематические классы.

    Для этого был написан \textit{Python} скрипт, использующий модель составленную из данных Википедии и НКРЯ за декабрь 2018 года представленную на ресурсе \textit{\href{https://rusvectores.org/ru/}{RusVectōrēs}} с идентификатором \textit{ruwikiruscorpora\textunderscore{}upos\textunderscore{}skipgram\textunderscore{}300\textunderscore{}2\textunderscore{}2019}. Данная модель была создана при помощи алгоритма Continuous Skipgram и содержит словарь объемом 248 978 слов, представленных эмбеддингами размерности 300. Токены в данной модели имеют структуру лемма\textunderscore{}POS --- это позволяет разрешить некоторые случаи омонимии (к примеру, Орел --- город и орел --- птица).

    Кластеризация проводилась на 3 различных наборах слов:
    
    \begin{itemize}
        \item железный, серебряный, стальной, твердый,
         добрый, твердый, выносливый, терпеливый,
         алмазный, алюминиевый, верный, пластиковый,
         жестокий, отважный, высокомерный, надменный,
         деревянный, золотой, кожаный, медный, 
         бронзовый, внимательный, раздражительный,
         хитрый, мудрый;
         
        \item киви, смородина, лиса, лисичка, 
         ара, клубника, земляника, малина, 
         черника, ежевика, огурец, облепиха, 
         перец, яблоко, черешня, крыжовник, 
         мандарин, мандаринка, ворон, сорока,
         беркут, орел, сокол, страус, эму,
         голубь, трясогузка, казуар;
         
        \item руль, штурвал, ручка, дверь, 
         кабина, кокпит, шасси, трансмиссия,
         фара, элерон, тормоз, крыло, 
         хвост, тяга, зеркало, колесо,
         шина, покрышка, кузов, оперение,
         крыло, планер, машина, капот, 
         бак, закрылок, тангаж.
    \end{itemize}

    Первый набор был создан для исследования того как сохраняются семантические связи у имен прилагательных и состоит из слов описывающих черты характера и материал предмета. Также в нем присутствуют семантические омонимы, которые принадлежат обеим группам: <<железный>>, <<стальной>>, <<золотой>>. Второй набор составлен аналогично первому. Он содержит существительные обозначающие животных и обозначающие съедобные предметы. Третий набор был создан для исследования того, как семантические связи сохраняются для узкоспециализированных слов в смежных направлениях. Он содержит слова, описывающие составные части автомобиля и самолета, а также пары гипоним-гипероним (<<оперение>> и <<элерон>>).

    Кластеризация слов в наборах была проведена с использованием двух алгоритмов: \textit{K-Means} и \textit{OPTICS}. Были использованы две меры семантической близости: косинусное расстояние и евклидово расстояние. Так как алгоритм K-Means предполагает использование только евклидовых и $L_p$ метрик, косинусное расстояние использовалось только в алгоритме \textit{OPTICS}.

	\begin{results}
        Метки классов полученных в результате работы программы можно увидеть в таблицах 1-3.

        \begin{center}
			\textbf{Таблица 1.}~ Метки классов слов из первого набора\\
			\begin{tblr}{width=\linewidth,
					colspec={|X[c]|X[c]|X[c]|X[c]|}} 
				\hline
				слово & K-Means & OPTICS (евклидово расстояние) & OPTICS (косинусное расстояние)\\
				\hline
                железный&0&0&-1\\
				\hline
                серебряный&0&0&0\\
				\hline
                стальной&0&0&0\\
				\hline
                твердый&1&1&-1\\
				\hline
                добрый&1&1&-1\\
				\hline
                выносливый&1&1&-1\\
				\hline
                терпеливый&1&1&-1\\
				\hline
                алмазный&0&0&-1\\
				\hline
                алюминиевый&0&0&0\\
				\hline
                верный&1&1&-1\\
				\hline
                пластиковый&0&0&0\\
				\hline
                жестокий&1&1&-1\\
				\hline
                отважный&1&1&-1\\
				\hline
                высокомерный&1&1&-1\\
				\hline
                надменный&1&1&-1\\
				\hline
                деревянный&0&0&0\\
				\hline
                золотой&0&0&0\\
				\hline
                кожаный&0&0&0\\
				\hline
                медный&0&0&0\\
				\hline
                бронзовый&0&0&-1\\
				\hline
                внимательный&1&1&-1\\
				\hline
                раздражительный&1&1&-1\\
				\hline
                хитрый&1&1&-1\\
				\hline
                мудрый&1&1&-1\\
				\hline
			\end{tblr}
        \end{center}
        
        \newpage

        \begin{center}
			\textbf{Таблица 2.}~ Метки классов слов из второго набора\\
			\begin{tblr}{width=\linewidth,
					colspec={|X[c]|X[c]|X[c]|X[c]|}} 
				\hline
				слово & K-Means & OPTICS (евклидово расстояние) & OPTICS (косинусное расстояние)\\
				\hline
                киви&0&-1&0\\
                \hline
                смородина&0&0&0\\
                \hline
                лиса&1&-1&0\\
                \hline
                лисичка&0&-1&0\\
                \hline
                ара&1&-1&0\\
                \hline
                клубника&0&0&0\\
                \hline
                земляника&0&0&0\\
                \hline
                малина&0&0&0\\
                \hline
                черника&0&0&0\\
                \hline
                ежевика&0&0&0\\
                \hline
                огурец&0&0&0\\
                \hline
                облепиха&0&0&0\\
                \hline
                перец&0&0&0\\
                \hline
                яблоко&0&0&0\\
                \hline
                черешня&0&0&0\\
                \hline
                крыжовник&0&0&0\\
                \hline
                мандарин&0&-1&0\\
                \hline
                мандаринка&1&-1&0\\
                \hline
                ворон&1&-1&0\\
                \hline
                сорока&1&-1&0\\
                \hline
                беркут&1&-1&0\\
                \hline
                орел&1&-1&0\\
                \hline
                сокол&1&-1&0\\
                \hline
                страус&1&-1&0\\
                \hline
                эму&1&-1&0\\
                \hline
                голубь&1&-1&0\\
                \hline
                трясогузка&1&-1&0\\
                \hline
                казуар&1&-1&0\\
                \hline
			\end{tblr}
        \end{center}
        
        \newpage

        \begin{center}
			\textbf{Таблица 3.}~ Метки классов слов из третьего набора\\
			\begin{tblr}{width=\linewidth,
					colspec={|X[c]|X[c]|X[c]|X[c]|}} 
				\hline
				слово & K-Means & OPTICS (евклидово расстояние) & OPTICS (косинусное расстояние)\\
				\hline
                руль&0&0&0\\
				\hline
                штурвал&0&0&0\\
				\hline
                ручка&1&-1&0\\
				\hline
                дверь&1&-1&0\\
				\hline
                кабина&0&0&0\\
				\hline
                кокпит&0&0&0\\
				\hline
                шасси&0&0&0\\
				\hline
                трансмиссия&0&0&0\\
				\hline
                фара&0&0&0\\
				\hline
                элерон&1&0&0\\
				\hline
                тормоз&0&0&0\\
				\hline
                крыло&1&-1&0\\
				\hline
                хвост&1&-1&0\\
				\hline
                тяга&0&-1&0\\
				\hline
                зеркало&1&-1&0\\
				\hline
                колесо&0&0&0\\
				\hline
                шина&0&0&0\\
				\hline
                покрышка&0&0&0\\
				\hline
                кузов&0&0&0\\
				\hline
                оперение&1&0&0\\
				\hline
                планер&1&0&0\\
				\hline
                машина&0&0&0\\
				\hline
                капот&0&0&0\\
				\hline
                бак&1&0&0\\
				\hline
                закрылок&1&0&0\\
				\hline
                тангаж&1&0&0\\
				\hline
			\end{tblr}
        \end{center}
        
        \newpage

        Согласно таблице 1, на первом наборе слов алгоритмы использующие евклидово расстояние дают одни и те же метки классов, однако использование косинусного расстояния дает иной результат. Слова <<алмазный>> и <<железный>> попадают в один кластер со словами обозначающими черты характера, а не материал предмета. Так же представляет интерес тот факт, что слова <<железный>> и <<стальной>> при кластеризации с использованием евклидова расстояния определяется в группу слов, обозначающими материалы, а не черты характера. Это может быть вызвано тем, что корпус на котором была обучена имеет преимущественно научный стиль.

        На втором наборе слов, согласно таблице 2, алгоритм \textit{K-Means} дал наилучшие результаты, хотя стоит отметить, что он отнес слово <<киви>> в группу слов, обозначающих предметы пищи, а не животных. Алгоритм \textit{OPTICS} с использованием евклидова расстояния в свою очередь отнес слова <<лиса>> и <<лисичка>>, а также <<мандарин>> и <<мандаринка>> в один класс. При использовании косинусного расстояния алгоритм определил все слова принадлежащими к одному и тому же классу.

        На третьем наборе слов каждый алгоритм кластеризации допустил хотя бы одну ошибку: \textit{K-Means} определил термины связанные с авиацией такие как <<кокпит>> или <<шасси>> в ту же группу, что и составляющие автомобиля, алгоритм \textit{OPTICS} при использовании косинусного расстояния не смог провести кластеризацию, а при использовании евклидова расстояния он определил гипоним и соответствующий ему гипероним в различные классы (<<оперение>> и <<элероны>>) и авиационные понятия такие как <<шасси>>, <<закрылок>> и <<тангаж>> в один кластер с автомобильными терминами. Описанные явления могли быть вызваны недостаточным количеством данных в корпусе на котором обучалась модель, что часто приводит к некачественным эмбеддингам.
	\end{results}

	\section*{Заключение}
	\addcontentsline{toc}{section}{\MakeUppercase{Заключение}}
	    Подытожив, хотелось бы отметить, что по результатам экспериментов наилучшим образом показал себя алгоритм \textit{K-Means}, использующий евклидово расстояние для измерения семантической близости слов. Стоит отметить, что у всех рассмотренных алгоритмов качество кластеризации узконаправленных терминов было ниже, чем более общих групп слов. Это может быть вызвано недостаточным числом употреблений данных слов в корпусе, на котором была обучена модель и, следовательно, более низким качеством полученных эмбеддингов. 
\end{document}