\documentclass[12pt, a4paper]{article}

\usepackage[russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{cmap}
\usepackage{setspace} 
\usepackage[a4paper,
			left=30mm,
			right=10mm,
			top=20mm,
			bottom=20mm]{geometry}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{cite}
\usepackage{subfigure,subcaption}
\usepackage{graphicx}
\usepackage{kprjHSE}
\usepackage{tabularray}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,      
	urlcolor=blue,
}

\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

\lstset{
	frame=single,
	basicstyle=\ttfamily,
	breaklines=true,
	tabsize=4
}

\LabWork
\title{Реферирование текста на русском языке}
\setcounter{MaxMatrixCols}{20}

\FirstAuthor{М.Д.~Кирдин}
\FirstConsultant{Е.И.~Большакова}
\discipline{Компьютерная лингвистика и анализ текстов}
\faculty{Факультет Компьютерных Наук}
\chair{Школа Анализа Данных и Искусственного Интеллекта}
\workyear{2025}

\onehalfspacing

\begin{document}
	\maketitle

	\tableofcontents
	
	\begin{introduction}
        Автоматическое реферирование текста является одной из основополагающих задач обработки естественного языка наряду с машинным переводом и распознаванием сущностей. Способы решения этой задачи делятся на две категории: извлекающие и генерирующие. Целью данной работы было провести сравнение этих подходов к решению задачи аннотирования текста. Извлекающие подходы были представлены алгоритмом \textit{TextRank}, а генерирующие подходы --- моделями с трасформерной архитектурой \textit{FRED-T5-Summarize} (1.4 миллиарда параметров), а также \textit{rut5-base} (246 миллионов параметров) с параметрами отрегулированными для решения задачи реферирования текстов на русском языке.  
	\end{introduction}
	
	\section{Ход работы}

    Для сравнения двух различных подходов было решено использовать специализированный датасет, предложенный Ахметгареевой А. и др. \cite{dataset}. Он состоит из 197 тыс. текстов в части предназначенной для обучения и 258 текстов проверенных вручную в части для тестов. Были взяты 40 первых примеров из тестового набора, аннотации, полученные в результате работы сравниваемых алгоритмов, были сохранены в виде текстовых файлов.

    \subsection{Реализация извлекающего алгоритма}
    Алгоритм \textit{TextRank} является модификацией алгоритма \textit{PageRank}, предложенного \textit{Google} в 1998 году. В данной работе используется вариант данного алгоритма для извлечения предложений. Он основан на построении графа при помощи алгоритма \textit{PageRank}, в котором вершинами являются предложения в тексте и извлечении \textit{n} вершин с наибольшим значением внутренней метрики. В рамках данной работы был написан скрипт на языке \textit{Python} с его реализацией, извлекающий ровно \textbf{3 лучших предложения}. 

    Для построения графа необходима матрица сходств предложений в реферируемом тексте. Она была получена как набор попарных косинусных расстояний между суммами эмбеддингов отдельных токенов. Эмбеддинги и токенизатор были взяты из библиотеки \textit{SpaCy}.

    \subsection{Реализация генерирующих алгоритмов}

    Был написан скрипт на языке \textit{Python}, который с помощью моделей \textit{FRED-T5-Summarize} и \textit{rut5-base} генерирует реферат текста. У последней, меньшей по размеру модели, параметры были отрегулированы(т.е. модель бы ла дообучена) на обучающей части выбранного датасета. Было рассмотрено несколько вариантов генерации ответов:
    
    \begin{itemize}
    	\item с префиксами на английском и декодированием с помощью лучевого поиска;
    	\item с префиксами на русском и декодированием с помощью лучевого поиска;
    	\item с префиксами на английском и декодированием с помощью \textit{promt lookup};
    	\item с префиксами на русском и декодированием с помощью \textit{promt lookup}.
    \end{itemize}
    Со значениям параметров декодирующего слоя можно ознакомиться в \hyperlink{params}{таблице A.1}. Такой выбор вариантов обусловлен тем, что некоторые модели (например, \textit{rut5-base}) являются получены обрезанием многоязычных версий моделей, обученных преимущественно на данных на английском языке, вследствие чего модели могут генерировать лучшие результаты при использовании английских токенов.

    \begin{results}
    Выбранный извлекающий алгоритм не может производить новые данные, а также использует предложения полностью вследствие чего в некоторых случаях длинные предложения (например, с объемными перечислениями) извлекаются из текста неизменными, что отрицательно влияет на качество аннотации. Например:
        
    \begin{center}
        \begin{tblr}{
                width=\linewidth,
                vlines, hlines,
                cell{1}{1-2}={font=\fontsize{9pt}{12pt}\selectfont},
                cell{2}{1-2}={font=\itshape\fontsize{6pt}{9pt}\selectfont},
                colspec={X[valign=m]X[valign=m]} 
        }	
        \SetCell{c}{Исходный текст} & \SetCell{c}{Аннотация}\\
        Мировой опыт свидетельствует, что для динамичного развития туризма необходимы следующие условия:

        – стабильная социально-экономическая ситуация (в мире в целом, в отдельной стране и конкретном регионе);

        – отсутствие административно-чиновничьих барьеров при перемещениях через границы и в период гостевого пребывания;

        – притягательные рекреационные ресурсы (природно-климатические и культурно-исторические);

        – развитая инфраструктура туризма и квалифицированные кадры;

        – высокий уровень сервиса, обеспечение комфортного проживания, гостеприимство, культура и профессионализм персонала;

        – комфортабельный и безопасный транспорт, надежная связь;

        – свобода перемещения и гарантии прав путешествующих, обеспечение их безопасности;

        – высокая ответственность туристских организаций и их структурных подразделений за проведение конкретных туров;

        – положительный туристский имидж территории, высокая репутация обслуживающих туристов фирм и компаний. & Мировой опыт свидетельствует, что для динамичного развития туризма необходимы следующие условия: 

        – стабильная социально-экономическая ситуация (в мире в целом, в отдельной стране и конкретном регионе); 

        – отсутствие административно-чиновничьих барьеров при перемещениях через границы и в период гостевого пребывания; 

        – притягательные рекреационные ресурсы (природно-климатические и культурно-исторические); 

        – развитая инфраструктура туризма и квалифицированные кадры; 

        – высокий уровень сервиса, обеспечение комфортного проживания, гостеприимство, культура и профессионализм персонала; 

        – комфортабельный и безопасный транспорт, надежная связь; 

        – свобода перемещения и гарантии прав путешествующих, обеспечение их безопасности; 

        – высокая ответственность туристских организаций и их структурных подразделений за проведение конкретных туров; 

        – положительный туристский имидж территории, высокая репутация обслуживающих туристов фирм и компаний.\\
        \end{tblr}
    \end{center}

    Однако в случае если текст достаточно объемный либо состоит из простых предложений качество реферирования значительно лучше:
        
    \begin{center}
        \begin{tblr}{ 
                width=\linewidth,
                vlines, hlines,
                cell{1}{1-2}={font=\fontsize{9pt}{12pt}\selectfont},
                cell{2}{1-2}={font=\itshape\fontsize{9pt}{12pt}\selectfont},
                colspec={X[valign=m]X[valign=m]} 
        } 
        \SetCell{c}{Исходный текст} & \SetCell{c}{Аннотация}\\
            Тануки - традиционные японские звери-оборотни, символизирующие счастье и благополучие, обычно выглядящие как енотовидные собаки. Второй по популярности зверь-оборотень после кицунэ. В отличие от кицунэ, образ тануки практически лишен негативной окраски. Считается, что тануки — большие любители саке. Поэтому без его присутствия нельзя сделать хорошего сакэ. По этой же причине фигурки тануки, порой весьма большие, являются украшением многих питейных заведений. Они изображают тануки толстяком-добряком с заметным брюшком. & Тануки - традиционные японские звери-оборотни, символизирующие счастье и благополучие, обычно выглядящие как енотовидные собаки. В отличие от кицунэ, образ тануки практически лишен негативной окраски. По этой же причине фигурки тануки, порой весьма большие, являются украшением многих питейных заведений.\\
        \end{tblr}
    \end{center}

    Качество аннотаций произведенных генерирующими алгоритмами было оценено с помощью метрики \textit{ROUGE} относительно предложенных в датасете аннотаций текста. Согласно \hyperlink{table1}{таблице 1}, в целом лучевой поиск с русскими префиксами дает лучшие результаты при реферировании текста. При этом, модель \textit{FRED-T5-Summarize} дает значительно лучшие результаты, чем модель \textit{rut5-base}, что может быть обусловлено их разницей в размере. Стоит заметить, что у обеих моделях во всех рассмотренных случаев со всеми рассмотренными метриками \textit{precision} больше, чем \textit{recall}. Это может быть объяснено тем, что сами сгенерированные аннотации короче предложенных в датасете аналогов.

    \begin{center}
        \hypertarget{table1}{\textbf{Таблица 1.}~Значения метрик \textit{ROUGE} для моделей \textit{FRED-T5-Summarize} и \textit{rut5-base} с отрегулированными параметрами}
    	\begin{tblr}{ 
            hlines, vlines,
            cells={font=\fontsize{9pt}{12pt}\selectfont},
            cell{1-2}{3-10}={font=\itshape\fontsize{9pt}{12pt}\selectfont},
            cell{3-Z}{1-2}={font=\itshape\fontsize{9pt}{12pt}\selectfont},
            width=\linewidth,
            colspec={*{2}{l} *{8}{c}}
    	} 
        \SetCell[r=2,c=2]{c}{Метрика} && \SetCell[c=4]{}{FRED-T5-Summarize} &&&& \SetCell[c=4]{}{rut5-base} &&&\\
            && ru, lookup & en, lookup & ru, beam & en, beam & ru, lookup & en, lookup & ru, beam & en, beam\\
        \SetCell[r=3]{}{\rotatebox{90}{rouge-1}} & recall & 0.21 & 0.12 & 0.38 & 0.13 & 0.06 & 0.09 & 0.15 & 0.09\\
        & precision & 0.63 & 0.56 & 0.88 & 0.52 & 0.55 & 0.56 & 0.75 & 0.53\\
        & f1-score & 0.29 & 0.19 & 0.50 & 0.20 & 0.11 & 0.15 & 0.25 & 0.15\\
        \SetCell[r=3]{}{\rotatebox{90}{rouge-2}} & recall & 0.11 & 0.06 & 0.32 & 0.07 & 0.03 & 0.04 & 0.09 & 0.04\\ 
        & precision & 0.37 & 0.32 & 0.79 & 0.29 & 0.29 & 0.26 & 0.54 & 0.27\\
        & f1-score & 0.15 & 0.09 & 0.43 & 0.10 & 0.05 & 0.05 & 0.15 & 0.07\\
        \SetCell[r=3]{}{\rotatebox{90}{rouge-l}} & recall & 0.20 & 0.12 & 0.37 & 0.12 & 0.06 & 0.08 & 0.15 & 0.09\\ 
        & precision & 0.60 & 0.54 & 0.88 & 0.50 & 0.53 & 0.53 & 0.74 & 0.52\\
        & f1-score & 0.27 & 0.18 & 0.50 & 0.19 & 0.10 & 0.14 & 0.24 & 0.14\\
        \end{tblr}
    \end{center}

    Рассмотрим некоторые рефераты, созданные рассматриваемыми моделями:
    \begin{center}
        \begin{tblr}{ 
                width=\linewidth,
                vlines, hlines,
                cell{1}{1-3}={font=\fontsize{9pt}{12pt}\selectfont},
                cell{2-Z}{1-3}={font=\itshape\fontsize{9pt}{12pt}\selectfont},
                colspec={X[valign=m]X[valign=m]X[valign=m]} 
        } 
        \SetCell{c}{Исходная аннотация} & \SetCell{c}{Аннотация FRED-T5-Summarize} & \SetCell{c}{Аннотация rut5-base}\\
        Готский язык - это древний германский язык, использовавшийся готами с I по VIII век. Он известен благодаря письменным памятникам IV-VI веков, включая перевод Библии, сделанный епископом Вульфилой, который также создал готский алфавит. Готы взаимодействовали с Римской империей и ассимилировались с местным населением, что привело к утрате их языка. Славянские языки, включая русский, заимствовали некоторые слова из готского языка. & Готский язык - это один из самых древних германских языков. Он был языком группы племен, которые обитали в I веке нашей эры по нижнему течению Вислы и Северном Причерноморье до VIII века на территории Восточной Римской империи (Византии). Славянские языки многое заимствовали оттуда: так русское слово «хлеб» — hlaifs является готским словом "hleaf". & В Европе готы изучали язык, который был основанным в первой половине нашей эры.
        \end{tblr}
    \end{center}

    Легко заметить, что генерируемые аннотации действительно короче тех, что предложены в самом датасете. Это может быть связано с ограниченным числом генерируемых токенов (512 штук). При этом также стоит обратить внимание на то, что, судя по аннотации \textit{rut5-base}, генерирующие модели подвержены галлюцинациям.

    Важно, что создание аннотаций с помощью генеративых алгоритмов занимало на порядок больше времени, чем с помощью извлекающего --- 10 и 3 минуты на 40 текстов для \textit{FRED-T5-Summarize} и \textit{rut5-base} соответственно и 2 минуты для алгоритма \textit{PageRank}. 
    \end{results}

	\section*{Заключение}
	\addcontentsline{toc}{section}{\MakeUppercase{Заключение}}
    
    Извлекающий алгормитм реферирования \textit{TextRank} в отличие от генерирующих алгоритмов требует гораздо меньше вычислительных мощностей и не подвержен галлюцинациям, но при этом в силу того что он работает с целыми предложениями он лучше всего работает с текстами содержащими большое количество простых предложений. При этом генерирующие модели могут создавать новые тексты и обобщать информацию, что делает результирующие аннотации короче и содержательнее.  

    \begin{thebibliography}{5}
        \bibitem{dataset}
        Akhmetgareeva A., Kuleshov I., Leschuk V., Abramov A., Fenogenova A., Towards Russian Summarization: can architecture solve data limitations problems? // \url{https://sberlabs.com/publications?publication=1600} (2024).

    \end{thebibliography}
    
    \section*{Приложение А}
    \addcontentsline{toc}{section}{\MakeUppercase{Приложение А}}

    \begin{center}
    	\hypertarget{params}{\textbf{Таблица A.1}~Значения параметров декодирующего слоя}
    	\begin{tblr}{ 
    		width=.80\linewidth,
    		colspec={|X[2,l]|X[c]|X[c]|} 
    	} 
    		\hline
    		Параметр & Лучевой поиск & \textit{Promt Lookup}\\
    		\hline
    		количество лучей & 4 & -\\
    		\hline
    		\textit{repetition\textunderscore{}penalty} & 10.0 & 1.5\\
    		\hline
    		\textit{length\textunderscore{}penalty} & 2.0 & -\\
    		\hline
    		модель-помощник & - & Модель без дообучения\\
    		\hline
    		\textit{length\textunderscore{}penalty} & 2.0 & -\\
    		\hline
    		температура & - & 0.4\\
    		\hline
    	\end{tblr}
    \end{center}
end{document}
